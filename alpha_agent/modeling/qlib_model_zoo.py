"""
Qlib Model Zoo - åŸºäºQlibæ¡†æ¶çš„å¤šæ¨¡å‹åŸºå‡†æµ‹è¯•

ä½¿ç”¨Qlibçš„æ¨¡å‹æ¨¡æ¿å’Œå·¥ä½œæµAPI:
- qlib.contrib.model ä¸­çš„æ¨¡å‹ (LGBModel, XGBModel, DNNModelç­‰)
- qlib.workflow è¿›è¡Œå®éªŒç®¡ç†
- init_instance_by_config ä»é…ç½®åˆå§‹åŒ–æ¨¡å‹
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, field
from pathlib import Path
import json
import time
import warnings
from datetime import datetime
import logging

warnings.filterwarnings('ignore')
logger = logging.getLogger(__name__)

# Qlibå¯¼å…¥
try:
    import qlib
    from qlib.utils import init_instance_by_config, flatten_dict
    from qlib.workflow import R
    from qlib.workflow.record_temp import SignalRecord
    from qlib.data.dataset import DatasetH
    QLIB_AVAILABLE = True
except ImportError:
    QLIB_AVAILABLE = False
    logger.warning("Qlibæœªå®‰è£…ï¼Œéƒ¨åˆ†åŠŸèƒ½ä¸å¯ç”¨")

from .config import OUTPUT_DIR, QLIB_CONFIG


# ===================== Qlib æ¨¡å‹é…ç½®æ¨¡æ¿ =====================

# LightGBM æ¨¡å‹é…ç½®
LGB_MODEL_CONFIG = {
    "class": "LGBModel",
    "module_path": "qlib.contrib.model.gbdt",
    "kwargs": {
        "loss": "mse",
        "colsample_bytree": 0.8879,
        "learning_rate": 0.0421,
        "subsample": 0.8789,
        "lambda_l1": 205.6999,
        "lambda_l2": 580.9768,
        "max_depth": 8,
        "num_leaves": 210,
        "num_threads": 20,
    },
}

# LightGBM è½»é‡ç‰ˆ
LGB_LIGHT_CONFIG = {
    "class": "LGBModel",
    "module_path": "qlib.contrib.model.gbdt",
    "kwargs": {
        "loss": "mse",
        "learning_rate": 0.05,
        "max_depth": 6,
        "num_leaves": 31,
        "n_estimators": 100,
        "num_threads": -1,
    },
}

# XGBoost æ¨¡å‹é…ç½®
XGB_MODEL_CONFIG = {
    "class": "XGBModel",
    "module_path": "qlib.contrib.model.xgboost",
    "kwargs": {
        "n_estimators": 200,
        "max_depth": 6,
        "learning_rate": 0.05,
        "subsample": 0.8,
        "colsample_bytree": 0.8,
        "reg_alpha": 0.1,
        "reg_lambda": 0.1,
        "n_jobs": -1,
    },
}

# CatBoost æ¨¡å‹é…ç½®
CATBOOST_MODEL_CONFIG = {
    "class": "CatBoostModel",
    "module_path": "qlib.contrib.model.catboost",
    "kwargs": {
        "iterations": 200,
        "depth": 6,
        "learning_rate": 0.05,
        "l2_leaf_reg": 3,
        "thread_count": -1,
        "verbose": False,
    },
}

# çº¿æ€§æ¨¡å‹é…ç½®
LINEAR_MODEL_CONFIG = {
    "class": "LinearModel",
    "module_path": "qlib.contrib.model.linear",
    "kwargs": {
        "estimator": "ridge",
        "alpha": 0.05,
    },
}

# MLP ç¥ç»ç½‘ç»œé…ç½®
MLP_MODEL_CONFIG = {
    "class": "DNNModelPytorch",
    "module_path": "qlib.contrib.model.pytorch_nn",
    "kwargs": {
        "d_feat": 158,  # ç‰¹å¾ç»´åº¦ï¼Œéœ€è¦æ ¹æ®å®é™…è°ƒæ•´
        "hidden_size": 64,
        "num_layers": 2,
        "dropout": 0.0,
        "n_epochs": 100,
        "lr": 0.001,
        "early_stop": 20,
        "batch_size": 2000,
        "metric": "loss",
        "loss": "mse",
        "GPU": 0,
    },
}

# LSTM æ¨¡å‹é…ç½®
LSTM_MODEL_CONFIG = {
    "class": "LSTM",
    "module_path": "qlib.contrib.model.pytorch_lstm",
    "kwargs": {
        "d_feat": 6,  # æ¯ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾æ•°
        "hidden_size": 64,
        "num_layers": 2,
        "dropout": 0.0,
        "n_epochs": 100,
        "lr": 0.001,
        "early_stop": 20,
        "batch_size": 2000,
        "metric": "loss",
        "loss": "mse",
        "GPU": 0,
    },
}

# GRU æ¨¡å‹é…ç½®
GRU_MODEL_CONFIG = {
    "class": "GRU",
    "module_path": "qlib.contrib.model.pytorch_gru",
    "kwargs": {
        "d_feat": 6,
        "hidden_size": 64,
        "num_layers": 2,
        "dropout": 0.0,
        "n_epochs": 100,
        "lr": 0.001,
        "early_stop": 20,
        "batch_size": 2000,
        "metric": "loss",
        "loss": "mse",
        "GPU": 0,
    },
}

# Transformer æ¨¡å‹é…ç½®
TRANSFORMER_MODEL_CONFIG = {
    "class": "Transformer",
    "module_path": "qlib.contrib.model.pytorch_transformer",
    "kwargs": {
        "d_feat": 6,
        "d_model": 64,
        "nhead": 2,
        "num_layers": 2,
        "dropout": 0.0,
        "n_epochs": 100,
        "lr": 0.0001,
        "early_stop": 20,
        "batch_size": 2000,
        "metric": "loss",
        "loss": "mse",
        "GPU": 0,
    },
}

# TabNet æ¨¡å‹é…ç½®
TABNET_MODEL_CONFIG = {
    "class": "TabNetModel",
    "module_path": "qlib.contrib.model.pytorch_tabnet",
    "kwargs": {
        "d_feat": 158,
        "n_d": 64,
        "n_a": 64,
        "n_steps": 3,
        "gamma": 1.3,
        "n_epochs": 100,
        "lr": 0.02,
        "batch_size": 2000,
        "GPU": 0,
    },
}

# Double Ensemble æ¨¡å‹é…ç½®
DOUBLE_ENSEMBLE_CONFIG = {
    "class": "DEnsembleModel",
    "module_path": "qlib.contrib.model.double_ensemble",
    "kwargs": {
        "base_model": "gbm",
        "loss": "mse",
        "num_models": 6,
        "enable_sr": True,
        "enable_fs": True,
        "alpha1": 1.0,
        "alpha2": 1.0,
        "bins_sr": 10,
        "bins_fs": 5,
        "decay": 0.5,
        "sample_ratios": [0.8, 0.7, 0.6, 0.5, 0.4, 0.3],
    },
}

# TCN æ—¶é—´å·ç§¯ç½‘ç»œ
TCN_MODEL_CONFIG = {
    "class": "TCN",
    "module_path": "qlib.contrib.model.pytorch_tcn",
    "kwargs": {
        "d_feat": 6,
        "num_channels": [32, 32, 32],
        "kernel_size": 3,
        "dropout": 0.0,
        "n_epochs": 100,
        "lr": 0.001,
        "early_stop": 20,
        "batch_size": 2000,
        "GPU": 0,
    },
}

# ALSTM æ³¨æ„åŠ›LSTM
ALSTM_MODEL_CONFIG = {
    "class": "ALSTM",
    "module_path": "qlib.contrib.model.pytorch_alstm",
    "kwargs": {
        "d_feat": 6,
        "hidden_size": 64,
        "num_layers": 2,
        "dropout": 0.0,
        "n_epochs": 100,
        "lr": 0.001,
        "early_stop": 20,
        "batch_size": 2000,
        "GPU": 0,
    },
}

# GATs å›¾æ³¨æ„åŠ›ç½‘ç»œ
GATS_MODEL_CONFIG = {
    "class": "GATs",
    "module_path": "qlib.contrib.model.pytorch_gats",
    "kwargs": {
        "d_feat": 6,
        "hidden_size": 64,
        "num_layers": 2,
        "dropout": 0.0,
        "n_epochs": 100,
        "lr": 0.001,
        "early_stop": 20,
        "batch_size": 2000,
        "GPU": 0,
    },
}

# TRA æ—¶é—´è·¯ç”±é€‚é…å™¨
TRA_MODEL_CONFIG = {
    "class": "TRA",
    "module_path": "qlib.contrib.model.pytorch_tra",
    "kwargs": {
        "d_feat": 6,
        "hidden_size": 64,
        "num_layers": 2,
        "dropout": 0.0,
        "n_epochs": 100,
        "lr": 0.001,
        "early_stop": 20,
        "batch_size": 2000,
        "GPU": 0,
    },
}

# Localformer å±€éƒ¨æ³¨æ„åŠ›
LOCALFORMER_MODEL_CONFIG = {
    "class": "Localformer",
    "module_path": "qlib.contrib.model.pytorch_localformer",
    "kwargs": {
        "d_feat": 6,
        "d_model": 64,
        "nhead": 4,
        "num_layers": 2,
        "dropout": 0.0,
        "n_epochs": 100,
        "lr": 0.0001,
        "early_stop": 20,
        "batch_size": 2000,
        "GPU": 0,
    },
}

# SFM çŠ¶æ€é¢‘ç‡è®°å¿†
SFM_MODEL_CONFIG = {
    "class": "SFM",
    "module_path": "qlib.contrib.model.pytorch_sfm",
    "kwargs": {
        "d_feat": 6,
        "hidden_size": 64,
        "n_epochs": 100,
        "lr": 0.001,
        "early_stop": 20,
        "batch_size": 2000,
        "GPU": 0,
    },
}

# HIST å†å²ä¿¡æ¯è‚¡ç¥¨è¶‹åŠ¿
HIST_MODEL_CONFIG = {
    "class": "HIST",
    "module_path": "qlib.contrib.model.pytorch_hist",
    "kwargs": {
        "d_feat": 6,
        "hidden_size": 64,
        "num_layers": 2,
        "dropout": 0.0,
        "n_epochs": 100,
        "lr": 0.0002,
        "early_stop": 20,
        "batch_size": 2000,
        "GPU": 0,
    },
}


# ===================== å®˜æ–¹åŸºå‡†æµ‹è¯•æ•°æ® (CSI300) =====================
# æ•°æ®æ¥æº: Qlibå®˜æ–¹æ–‡æ¡£
# æµ‹è¯•åŒºé—´: 2017-01-01 ~ 2020-08-01

OFFICIAL_BENCHMARK_ALPHA158 = {
    # æ¨¡å‹: (IC, ICIR, RankIC, RankICIR, AnnRet, IR, MaxDD)
    "double_ensemble": (0.0521, 0.4223, 0.0502, 0.4117, 0.1158, 1.3432, -0.0920),
    "lgb": (0.0448, 0.3660, 0.0469, 0.3877, 0.0901, 1.0164, -0.1038),
    "mlp": (0.0376, 0.2846, 0.0429, 0.3220, 0.0895, 1.1408, -0.1103),
    "xgb": (0.0498, 0.3779, 0.0505, 0.4131, 0.0780, 0.9070, -0.1168),
    "catboost": (0.0481, 0.3366, 0.0454, 0.3311, 0.0765, 0.8032, -0.1092),
    "tra": (0.0440, 0.3535, 0.0540, 0.4451, 0.0718, 1.0835, -0.0760),
    "linear": (0.0397, 0.3000, 0.0472, 0.3531, 0.0692, 0.9209, -0.1509),
    "gats": (0.0349, 0.2511, 0.0462, 0.3564, 0.0497, 0.7338, -0.0777),
    "alstm": (0.0362, 0.2789, 0.0463, 0.3661, 0.0470, 0.6992, -0.1072),
    "sfm": (0.0379, 0.2959, 0.0464, 0.3825, 0.0465, 0.5672, -0.1282),
    "localformer": (0.0356, 0.2756, 0.0468, 0.3784, 0.0438, 0.6600, -0.0952),
    "lstm": (0.0318, 0.2367, 0.0435, 0.3389, 0.0381, 0.5561, -0.1207),
    "gru": (0.0315, 0.2450, 0.0428, 0.3440, 0.0344, 0.5160, -0.1017),
    "transformer": (0.0264, 0.2053, 0.0407, 0.3273, 0.0273, 0.3970, -0.1101),
    "tcn": (0.0279, 0.2181, 0.0421, 0.3429, 0.0262, 0.4133, -0.1090),
    "tabnet": (0.0204, 0.1554, 0.0333, 0.2552, 0.0227, 0.3676, -0.1089),
}

OFFICIAL_BENCHMARK_ALPHA360 = {
    # æ¨¡å‹: (IC, ICIR, RankIC, RankICIR, AnnRet, IR, MaxDD)
    "hist": (0.0522, 0.3530, 0.0667, 0.4576, 0.0987, 1.3726, -0.0681),
    "igmtf": (0.0480, 0.3589, 0.0606, 0.4773, 0.0946, 1.3509, -0.0716),
    "tra": (0.0485, 0.3787, 0.0587, 0.4756, 0.0920, 1.2789, -0.0834),
    "tcts": (0.0508, 0.3931, 0.0599, 0.4756, 0.0893, 1.2256, -0.0857),
    "gats": (0.0476, 0.3508, 0.0598, 0.4604, 0.0824, 1.1079, -0.0894),
    "adarnn": (0.0464, 0.3619, 0.0539, 0.4287, 0.0753, 1.0200, -0.0936),
    "gru": (0.0493, 0.3772, 0.0584, 0.4638, 0.0720, 0.9730, -0.0821),
    "add": (0.0430, 0.3188, 0.0559, 0.4301, 0.0667, 0.8992, -0.0855),
    "lstm": (0.0448, 0.3474, 0.0549, 0.4366, 0.0647, 0.8963, -0.0875),
    "alstm": (0.0497, 0.3829, 0.0599, 0.4736, 0.0626, 0.8651, -0.0994),
    "tcn": (0.0441, 0.3301, 0.0519, 0.4130, 0.0604, 0.8295, -0.1018),
    "lgb": (0.0400, 0.3037, 0.0499, 0.4042, 0.0558, 0.7632, -0.0659),
    "double_ensemble": (0.0390, 0.2946, 0.0486, 0.3836, 0.0462, 0.6151, -0.0915),
    "xgb": (0.0394, 0.2909, 0.0448, 0.3679, 0.0344, 0.4527, -0.1004),
    "catboost": (0.0378, 0.2714, 0.0467, 0.3659, 0.0292, 0.3781, -0.0862),
    "localformer": (0.0404, 0.2932, 0.0542, 0.4110, 0.0246, 0.3211, -0.1095),
    "mlp": (0.0273, 0.1870, 0.0396, 0.2910, 0.0029, 0.0274, -0.1385),
    "transformer": (0.0114, 0.0716, 0.0327, 0.2248, -0.0270, -0.3378, -0.1653),
    "tabnet": (0.0099, 0.0593, 0.0290, 0.1887, -0.0369, -0.3892, -0.2145),
}

# æ¨èæ¨¡å‹ç»„åˆ
RECOMMENDED_MODEL_SETS = {
    "fast": ["lgb_light"],
    "standard": ["lgb", "xgb", "linear"],
    "full": ["lgb", "xgb", "catboost", "mlp", "double_ensemble"],
    "deep": ["lgb", "lstm", "gru", "transformer", "gats"],
    "sota": ["double_ensemble", "tra", "hist", "gats", "alstm"],
}


# ===================== æ¨¡å‹Zooç±» =====================

@dataclass
class QlibModelResult:
    """Qlibæ¨¡å‹ç»“æœ"""
    name: str
    category: str
    # æŒ‡æ ‡
    ic: float = 0.0
    icir: float = 0.0
    rank_ic: float = 0.0
    rank_icir: float = 0.0
    rmse: float = 0.0
    mae: float = 0.0
    # å›æµ‹æŒ‡æ ‡
    annualized_return: float = 0.0
    information_ratio: float = 0.0
    max_drawdown: float = 0.0
    # è®­ç»ƒä¿¡æ¯
    train_time: float = 0.0
    config: Dict = field(default_factory=dict)
    status: str = "pending"
    error: str = ""


class QlibModelZoo:
    """Qlibæ¨¡å‹åŠ¨ç‰©å›­"""
    
    # æ¨¡å‹é…ç½®æ˜ å°„
    MODEL_CONFIGS = {
        # æ ‘æ¨¡å‹
        "lgb": ("LightGBM", "boosting", LGB_MODEL_CONFIG),
        "lgb_light": ("LightGBM_Light", "boosting", LGB_LIGHT_CONFIG),
        "xgb": ("XGBoost", "boosting", XGB_MODEL_CONFIG),
        "catboost": ("CatBoost", "boosting", CATBOOST_MODEL_CONFIG),
        # çº¿æ€§æ¨¡å‹
        "linear": ("Linear", "linear", LINEAR_MODEL_CONFIG),
        # ç¥ç»ç½‘ç»œ - åŸºç¡€
        "mlp": ("MLP", "nn", MLP_MODEL_CONFIG),
        "lstm": ("LSTM", "nn", LSTM_MODEL_CONFIG),
        "gru": ("GRU", "nn", GRU_MODEL_CONFIG),
        "transformer": ("Transformer", "nn", TRANSFORMER_MODEL_CONFIG),
        "tabnet": ("TabNet", "nn", TABNET_MODEL_CONFIG),
        # ç¥ç»ç½‘ç»œ - é«˜çº§
        "tcn": ("TCN", "nn", TCN_MODEL_CONFIG),
        "alstm": ("ALSTM", "nn", ALSTM_MODEL_CONFIG),
        "gats": ("GATs", "graph", GATS_MODEL_CONFIG),
        "tra": ("TRA", "nn", TRA_MODEL_CONFIG),
        "localformer": ("Localformer", "nn", LOCALFORMER_MODEL_CONFIG),
        "sfm": ("SFM", "nn", SFM_MODEL_CONFIG),
        "hist": ("HIST", "graph", HIST_MODEL_CONFIG),
        # é›†æˆæ¨¡å‹
        "double_ensemble": ("DoubleEnsemble", "ensemble", DOUBLE_ENSEMBLE_CONFIG),
    }
    
    # å®˜æ–¹åŸºå‡†æ•°æ®
    OFFICIAL_BENCHMARK = {
        "alpha158": OFFICIAL_BENCHMARK_ALPHA158,
        "alpha360": OFFICIAL_BENCHMARK_ALPHA360,
    }
    
    @classmethod
    def list_models(cls) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰æ¨¡å‹"""
        return list(cls.MODEL_CONFIGS.keys())
    
    @classmethod
    def get_config(cls, name: str) -> Optional[Dict]:
        """è·å–æ¨¡å‹é…ç½®"""
        if name in cls.MODEL_CONFIGS:
            return cls.MODEL_CONFIGS[name][2].copy()
        return None
    
    @classmethod
    def get_model_info(cls, name: str) -> Optional[Tuple[str, str, Dict]]:
        """è·å–æ¨¡å‹ä¿¡æ¯: (æ˜¾ç¤ºå, ç±»åˆ«, é…ç½®)"""
        return cls.MODEL_CONFIGS.get(name)
    
    @classmethod
    def get_official_benchmark(cls, dataset: str = "alpha158", model: str = None) -> Dict:
        """
        è·å–å®˜æ–¹åŸºå‡†æµ‹è¯•æ•°æ®
        
        å‚æ•°:
            dataset: "alpha158" æˆ– "alpha360"
            model: æ¨¡å‹åç§° (å¯é€‰ï¼Œä¸æŒ‡å®šåˆ™è¿”å›å…¨éƒ¨)
        
        è¿”å›:
            dict: {model: (IC, ICIR, RankIC, RankICIR, AnnRet, IR, MaxDD)}
        """
        benchmark = cls.OFFICIAL_BENCHMARK.get(dataset, {})
        if model:
            return {model: benchmark.get(model)}
        return benchmark
    
    @classmethod
    def get_recommended_models(cls, preset: str = "standard") -> List[str]:
        """
        è·å–æ¨èæ¨¡å‹ç»„åˆ
        
        å‚æ•°:
            preset: "fast", "standard", "full", "deep", "sota"
        """
        return RECOMMENDED_MODEL_SETS.get(preset, RECOMMENDED_MODEL_SETS["standard"])
    
    @classmethod
    def print_official_benchmark(cls, dataset: str = "alpha158"):
        """æ‰“å°å®˜æ–¹åŸºå‡†æµ‹è¯•è¡¨"""
        benchmark = cls.OFFICIAL_BENCHMARK.get(dataset, {})
        if not benchmark:
            print(f"æœªæ‰¾åˆ°æ•°æ®é›†: {dataset}")
            return
        
        print(f"\n{'='*90}")
        print(f"ã€Qlibå®˜æ–¹åŸºå‡†æµ‹è¯• - {dataset.upper()} (CSI300)ã€‘")
        print(f"{'='*90}")
        print(f"{'æ¨¡å‹':<20} {'IC':>8} {'ICIR':>8} {'RankIC':>8} {'å¹´åŒ–æ”¶ç›Š':>10} {'IR':>8} {'æœ€å¤§å›æ’¤':>10}")
        print("-" * 90)
        
        # æŒ‰å¹´åŒ–æ”¶ç›Šæ’åº
        sorted_models = sorted(benchmark.items(), key=lambda x: x[1][4], reverse=True)
        
        for model, metrics in sorted_models:
            ic, icir, rank_ic, rank_icir, ann_ret, ir, max_dd = metrics
            print(f"{model:<20} {ic:>8.4f} {icir:>8.4f} {rank_ic:>8.4f} {ann_ret:>10.2%} {ir:>8.4f} {max_dd:>10.2%}")
        
        print(f"{'='*90}")
        
        # Top 3
        top3 = sorted_models[:3]
        print(f"\nğŸ† Top 3 æ¨¡å‹ (æŒ‰å¹´åŒ–æ”¶ç›Š):")
        for i, (model, metrics) in enumerate(top3, 1):
            print(f"   {i}. {model}: å¹´åŒ–{metrics[4]:.2%}, IC={metrics[0]:.4f}, IR={metrics[5]:.4f}")
    
    @classmethod
    def compare_with_official(cls, results: Dict[str, 'QlibModelResult'], dataset: str = "alpha158"):
        """
        ä¸å®˜æ–¹åŸºå‡†å¯¹æ¯”
        
        å‚æ•°:
            results: å®é™…æµ‹è¯•ç»“æœ
            dataset: å¯¹æ¯”æ•°æ®é›†
        """
        benchmark = cls.OFFICIAL_BENCHMARK.get(dataset, {})
        
        print(f"\n{'='*100}")
        print(f"ã€ä¸å®˜æ–¹åŸºå‡†å¯¹æ¯” - {dataset.upper()}ã€‘")
        print(f"{'='*100}")
        print(f"{'æ¨¡å‹':<15} {'å®æµ‹IC':>10} {'å®˜æ–¹IC':>10} {'å·®å¼‚':>10} {'å®æµ‹ICIR':>10} {'å®˜æ–¹ICIR':>10}")
        print("-" * 100)
        
        for model_name, result in results.items():
            if model_name in benchmark:
                official = benchmark[model_name]
                ic_diff = result.ic - official[0]
                print(f"{model_name:<15} {result.ic:>10.4f} {official[0]:>10.4f} {ic_diff:>+10.4f} {result.icir:>10.4f} {official[1]:>10.4f}")
            else:
                print(f"{model_name:<15} {result.ic:>10.4f} {'N/A':>10} {'':>10} {result.icir:>10.4f} {'N/A':>10}")
        
        print(f"{'='*100}")


class QlibBenchmark:
    """Qlibå¤šæ¨¡å‹åŸºå‡†æµ‹è¯•"""
    
    def __init__(
        self,
        models: List[str] = None,
        qlib_initialized: bool = False,
    ):
        """
        åˆå§‹åŒ–åŸºå‡†æµ‹è¯•
        
        å‚æ•°:
            models: æ¨¡å‹åˆ—è¡¨ (é»˜è®¤ä½¿ç”¨ä¸»è¦æ¨¡å‹)
            qlib_initialized: Qlibæ˜¯å¦å·²åˆå§‹åŒ–
        """
        if not QLIB_AVAILABLE:
            raise ImportError("è¯·å…ˆå®‰è£…Qlib: pip install pyqlib")
        
        # é»˜è®¤æ¨¡å‹åˆ—è¡¨ (æ ‘æ¨¡å‹ä¸ºä¸»ï¼Œç¥ç»ç½‘ç»œå¯é€‰)
        self.model_names = models or ["lgb", "lgb_light", "xgb", "linear"]
        self.qlib_initialized = qlib_initialized
        
        self.results: Dict[str, QlibModelResult] = {}
        self.predictions: Dict[str, pd.DataFrame] = {}
    
    def init_qlib(self, provider_uri: str = None):
        """åˆå§‹åŒ–Qlib"""
        if self.qlib_initialized:
            return
        
        provider_uri = provider_uri or QLIB_CONFIG.get('provider_uri', '~/.qlib/qlib_data/cn_data')
        region = QLIB_CONFIG.get('region', 'cn')
        
        qlib.init(provider_uri=provider_uri, region=region)
        self.qlib_initialized = True
        logger.info(f"Qlibå·²åˆå§‹åŒ–: {provider_uri}")
    
    def create_dataset_config(
        self,
        handler_class: str = "Alpha158",
        handler_module: str = "qlib.contrib.data.handler",
        instruments: str = "csi300",
        train_period: Tuple[str, str] = ("2008-01-01", "2014-12-31"),
        valid_period: Tuple[str, str] = ("2015-01-01", "2016-12-31"),
        test_period: Tuple[str, str] = ("2017-01-01", "2020-08-01"),
    ) -> Dict:
        """åˆ›å»ºæ•°æ®é›†é…ç½®"""
        return {
            "class": "DatasetH",
            "module_path": "qlib.data.dataset",
            "kwargs": {
                "handler": {
                    "class": handler_class,
                    "module_path": handler_module,
                    "kwargs": {
                        "start_time": train_period[0],
                        "end_time": test_period[1],
                        "fit_start_time": train_period[0],
                        "fit_end_time": train_period[1],
                        "instruments": instruments,
                    },
                },
                "segments": {
                    "train": train_period,
                    "valid": valid_period,
                    "test": test_period,
                },
            },
        }
    
    def run_single_model(
        self,
        model_name: str,
        dataset_config: Dict,
        experiment_name: str = "benchmark",
    ) -> QlibModelResult:
        """è¿è¡Œå•ä¸ªæ¨¡å‹"""
        model_info = QlibModelZoo.get_model_info(model_name)
        if model_info is None:
            return QlibModelResult(
                name=model_name, category="unknown",
                status="error", error="æ¨¡å‹ä¸å­˜åœ¨"
            )
        
        display_name, category, model_config = model_info
        result = QlibModelResult(
            name=display_name,
            category=category,
            config=model_config.copy(),
        )
        
        try:
            start_time = time.time()
            
            # åˆå§‹åŒ–æ¨¡å‹å’Œæ•°æ®é›†
            model = init_instance_by_config(model_config)
            dataset = init_instance_by_config(dataset_config)
            
            # å¯åŠ¨å®éªŒ
            with R.start(experiment_name=f"{experiment_name}_{model_name}"):
                # è®°å½•å‚æ•°
                R.log_params(**flatten_dict({"model": model_config}))
                
                # è®­ç»ƒ
                model.fit(dataset)
                
                # é¢„æµ‹
                pred = model.predict(dataset)
                self.predictions[model_name] = pred
                
                # ä¿å­˜ä¿¡å·è®°å½•
                recorder = R.get_recorder()
                sr = SignalRecord(model, dataset, recorder)
                sr.generate()
                
                # ä½¿ç”¨ SigAnaRecord è®¡ç®— IC æŒ‡æ ‡
                try:
                    from qlib.workflow.record_temp import SigAnaRecord
                    import pandas as pd
                    
                    sar = SigAnaRecord(recorder)
                    sar.generate()
                    
                    # ic.pkl æ˜¯æ¯æ—¥ IC çš„ Seriesï¼Œric.pkl æ˜¯æ¯æ—¥ Rank IC çš„ Series
                    ic_series = recorder.load_object("sig_analysis/ic.pkl")
                    if ic_series is not None and isinstance(ic_series, pd.Series) and len(ic_series) > 0:
                        result.ic = float(ic_series.mean())
                        result.icir = float(ic_series.mean() / ic_series.std()) if ic_series.std() > 0 else 0
                    
                    # åŠ è½½ Rank IC
                    try:
                        ric_series = recorder.load_object("sig_analysis/ric.pkl")
                        if ric_series is not None and isinstance(ric_series, pd.Series) and len(ric_series) > 0:
                            result.rank_ic = float(ric_series.mean())
                            result.rank_icir = float(ric_series.mean() / ric_series.std()) if ric_series.std() > 0 else 0
                    except Exception:
                        pass  # Rank IC æ–‡ä»¶å¯èƒ½ä¸å­˜åœ¨
                    
                    # ä½¿ç”¨ PortAnaRecord è¿›è¡Œç­–ç•¥å›æµ‹ï¼ˆè®¡ç®—å¹´åŒ–æ”¶ç›Šã€å¤æ™®ã€æœ€å¤§å›æ’¤ï¼‰
                    try:
                        from qlib.workflow.record_temp import PortAnaRecord
                        
                        # PortAnaRecord éœ€è¦çš„é…ç½®æ ¼å¼
                        port_analysis_config = {
                            "strategy": {
                                "class": "TopkDropoutStrategy",
                                "module_path": "qlib.contrib.strategy",
                                "kwargs": {
                                    "signal": "<PRED>",
                                    "topk": 30,
                                    "n_drop": 5,
                                },
                            },
                            "backtest": {
                                "start_time": dataset_config["kwargs"]["segments"]["test"][0],
                                "end_time": dataset_config["kwargs"]["segments"]["test"][1],
                                "account": 100000000,
                                "benchmark": "SH000300",
                                "exchange_kwargs": {
                                    "freq": "day",
                                    "limit_threshold": 0.095,
                                    "deal_price": "close",
                                    "open_cost": 0.0005,
                                    "close_cost": 0.0015,
                                    "min_cost": 5,
                                },
                            },
                        }
                        
                        # æ‰§è¡Œå›æµ‹
                        par = PortAnaRecord(recorder, port_analysis_config)
                        par.generate()
                        
                        # åŠ è½½åˆ†æç»“æœ (port_analysis_1day.pkl åŒ…å«å¹´åŒ–æ”¶ç›Šç­‰æŒ‡æ ‡)
                        analysis_df = recorder.load_object("portfolio_analysis/port_analysis_1day.pkl")
                        if analysis_df is not None:
                            # MultiIndex: (metric_type, metric_name) -> 'risk' column
                            try:
                                result.annualized_return = float(analysis_df.loc[("excess_return_with_cost", "annualized_return"), "risk"])
                                result.information_ratio = float(analysis_df.loc[("excess_return_with_cost", "information_ratio"), "risk"])
                                result.max_drawdown = float(abs(analysis_df.loc[("excess_return_with_cost", "max_drawdown"), "risk"]))
                                result.sharpe = result.information_ratio
                            except Exception:
                                # å¤‡ç”¨ï¼šè¯»å–ä¸å«æˆæœ¬çš„
                                try:
                                    result.annualized_return = float(analysis_df.loc[("excess_return_without_cost", "annualized_return"), "risk"])
                                    result.information_ratio = float(analysis_df.loc[("excess_return_without_cost", "information_ratio"), "risk"])
                                    result.max_drawdown = float(abs(analysis_df.loc[("excess_return_without_cost", "max_drawdown"), "risk"]))
                                    result.sharpe = result.information_ratio
                                except Exception:
                                    pass
                        
                        # åŠ è½½æ¢æ‰‹ç‡
                        report_df = recorder.load_object("portfolio_analysis/report_normal_1day.pkl")
                        if report_df is not None and "turnover" in report_df.columns:
                            result.turnover = float(report_df["turnover"].mean())
                    except Exception as port_err:
                        logger.debug(f"PortAnaRecord å›æµ‹è·³è¿‡: {port_err}")
                        
                except Exception as sig_err:
                    # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥è®¡ç®— IC
                    logger.warning(f"SigAnaRecordå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {sig_err}")
                    try:
                        test_label = dataset.prepare("test", col_set=["label"], data_key="infer")
                        if test_label is not None and len(pred) > 0:
                            label = test_label.iloc[:, 0]
                            common_idx = pred.index.intersection(label.index)
                            if len(common_idx) > 10:
                                p, l = pred.loc[common_idx], label.loc[common_idx]
                                daily_ic = p.groupby(level='datetime').apply(lambda x: x.corr(l.loc[x.index]))
                                result.ic = float(daily_ic.mean())
                                result.icir = float(daily_ic.mean() / daily_ic.std()) if daily_ic.std() > 0 else 0
                    except Exception as calc_err:
                        logger.warning(f"ICè®¡ç®—å¤±è´¥: {calc_err}")
            
            result.train_time = time.time() - start_time
            result.status = "success"
            
        except Exception as e:
            result.status = "error"
            result.error = str(e)
            logger.error(f"æ¨¡å‹ {model_name} è®­ç»ƒå¤±è´¥: {e}")
        
        return result
    
    def run(
        self,
        dataset_config: Dict = None,
        experiment_name: str = "benchmark",
        **dataset_kwargs,
    ) -> pd.DataFrame:
        """
        è¿è¡Œæ‰€æœ‰æ¨¡å‹åŸºå‡†æµ‹è¯•
        
        å‚æ•°:
            dataset_config: æ•°æ®é›†é…ç½® (å¯é€‰)
            experiment_name: å®éªŒåç§°
            **dataset_kwargs: ä¼ é€’ç»™create_dataset_configçš„å‚æ•°
        
        è¿”å›:
            æ¨¡å‹å¯¹æ¯”è¡¨DataFrame
        """
        print("\n" + "="*70)
        print("ã€Qlib å¤šæ¨¡å‹åŸºå‡†æµ‹è¯•ã€‘")
        print("="*70)
        print(f"ğŸ“Š æ¨¡å‹æ•°: {len(self.model_names)}")
        print(f"ğŸ“Š æ¨¡å‹: {', '.join(self.model_names)}")
        
        # ç¡®ä¿Qlibå·²åˆå§‹åŒ–
        self.init_qlib()
        
        # åˆ›å»ºæ•°æ®é›†é…ç½®
        if dataset_config is None:
            dataset_config = self.create_dataset_config(**dataset_kwargs)
        
        # è¿è¡Œæ‰€æœ‰æ¨¡å‹
        for i, model_name in enumerate(self.model_names, 1):
            print(f"\n[{i}/{len(self.model_names)}] è®­ç»ƒ {model_name}...")
            result = self.run_single_model(model_name, dataset_config, experiment_name)
            self.results[model_name] = result
            
            if result.status == "success":
                print(f"  âœ“ IC={result.ic:.4f}, ICIR={result.icir:.4f}, è€—æ—¶={result.train_time:.1f}s")
            else:
                print(f"  âœ— {result.error[:50]}")
        
        # ç”Ÿæˆå¯¹æ¯”è¡¨
        comparison = self._generate_comparison()
        self.print_summary()
        self.save_results()
        
        return comparison
    
    def _generate_comparison(self) -> pd.DataFrame:
        """ç”Ÿæˆå¯¹æ¯”è¡¨"""
        records = []
        for name, result in self.results.items():
            records.append({
                "æ¨¡å‹": result.name,
                "ç±»åˆ«": result.category,
                "IC": result.ic,
                "ICIR": result.icir,
                "Rank_IC": result.rank_ic,
                "Rank_ICIR": result.rank_icir,
                "å¹´åŒ–æ”¶ç›Š": result.annualized_return,
                "ä¿¡æ¯æ¯”ç‡": result.information_ratio,
                "æœ€å¤§å›æ’¤": result.max_drawdown,
                "è®­ç»ƒæ—¶é—´": result.train_time,
                "çŠ¶æ€": result.status,
            })
        
        df = pd.DataFrame(records)
        df = df.sort_values("ICIR", ascending=False)
        return df
    
    def get_best_model(self, metric: str = "icir") -> str:
        """è·å–æœ€ä½³æ¨¡å‹"""
        best_name = None
        best_value = -np.inf
        
        for name, result in self.results.items():
            if result.status != "success":
                continue
            value = getattr(result, metric, 0)
            if value > best_value:
                best_value = value
                best_name = name
        
        return best_name
    
    def print_summary(self):
        """æ‰“å°æ‘˜è¦"""
        print("\n" + "="*70)
        print("ã€Qlib æ¨¡å‹å¯¹æ¯”ç»“æœã€‘")
        print("="*70)
        
        comparison = self._generate_comparison()
        print(comparison.to_string(index=False))
        
        best = self.get_best_model("icir")
        if best:
            print(f"\nğŸ† æœ€ä½³æ¨¡å‹ (ICIR): {self.results[best].name}")
    
    def save_results(self, path: Path = None):
        """ä¿å­˜ç»“æœ"""
        if path is None:
            path = OUTPUT_DIR / "qlib_benchmark_results.json"
        
        data = {
            "timestamp": datetime.now().isoformat(),
            "models": {
                name: {
                    "name": r.name,
                    "category": r.category,
                    "ic": r.ic,
                    "icir": r.icir,
                    "train_time": r.train_time,
                    "status": r.status,
                }
                for name, r in self.results.items()
            },
            "best_model": self.get_best_model("icir"),
        }
        
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“ ç»“æœå·²ä¿å­˜: {path}")


# ===================== ä¾¿æ·å‡½æ•° =====================

def run_qlib_benchmark(
    models: List[str] = None,
    instruments: str = "csi300",
    train_period: Tuple[str, str] = ("2008-01-01", "2014-12-31"),
    valid_period: Tuple[str, str] = ("2015-01-01", "2016-12-31"),
    test_period: Tuple[str, str] = ("2017-01-01", "2020-08-01"),
) -> Tuple[pd.DataFrame, str]:
    """
    ä¾¿æ·å‡½æ•°: è¿è¡ŒQlibåŸºå‡†æµ‹è¯•
    
    è¿”å›:
        comparison: æ¨¡å‹å¯¹æ¯”è¡¨
        best_model: æœ€ä½³æ¨¡å‹åç§°
    """
    benchmark = QlibBenchmark(models=models)
    comparison = benchmark.run(
        instruments=instruments,
        train_period=train_period,
        valid_period=valid_period,
        test_period=test_period,
    )
    best = benchmark.get_best_model("icir")
    
    return comparison, best


def generate_workflow_config(
    model_name: str,
    output_path: Path = None,
    instruments: str = "csi300",
    **kwargs,
) -> Dict:
    """
    ç”ŸæˆQlib workflowé…ç½®æ–‡ä»¶
    
    å¯ç”¨äº qrun å‘½ä»¤è¡Œå·¥å…·
    """
    model_info = QlibModelZoo.get_model_info(model_name)
    if model_info is None:
        raise ValueError(f"æœªçŸ¥æ¨¡å‹: {model_name}")
    
    _, _, model_config = model_info
    
    config = {
        "qlib_init": {
            "provider_uri": QLIB_CONFIG.get("provider_uri", "~/.qlib/qlib_data/cn_data"),
            "region": QLIB_CONFIG.get("region", "cn"),
        },
        "market": instruments,
        "benchmark": "SH000300" if instruments == "csi300" else "SH000905",
        "data_handler_config": {
            "start_time": kwargs.get("start_time", "2008-01-01"),
            "end_time": kwargs.get("end_time", "2020-08-01"),
            "fit_start_time": kwargs.get("fit_start_time", "2008-01-01"),
            "fit_end_time": kwargs.get("fit_end_time", "2014-12-31"),
            "instruments": instruments,
        },
        "task": {
            "model": model_config,
            "dataset": {
                "class": "DatasetH",
                "module_path": "qlib.data.dataset",
                "kwargs": {
                    "handler": {
                        "class": "Alpha158",
                        "module_path": "qlib.contrib.data.handler",
                    },
                    "segments": {
                        "train": (kwargs.get("train_start", "2008-01-01"), 
                                 kwargs.get("train_end", "2014-12-31")),
                        "valid": (kwargs.get("valid_start", "2015-01-01"),
                                 kwargs.get("valid_end", "2016-12-31")),
                        "test": (kwargs.get("test_start", "2017-01-01"),
                                kwargs.get("test_end", "2020-08-01")),
                    },
                },
            },
        },
    }
    
    if output_path:
        import yaml
        with open(output_path, "w") as f:
            yaml.dump(config, f, default_flow_style=False)
        print(f"é…ç½®å·²ä¿å­˜: {output_path}")
    
    return config
