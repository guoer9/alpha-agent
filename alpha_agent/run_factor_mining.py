#!/usr/bin/env python
"""
Alpha Agent å› å­æŒ–æ˜ç³»ç»Ÿ

å®Œæ•´çš„å› å­æŒ–æ˜æµç¨‹:
1. LLMæ¢ç´¢ - ä½¿ç”¨DashScope/OpenAIç”Ÿæˆå› å­
2. GPç²¾ç‚¼ - é—ä¼ ç®—æ³•ä¼˜åŒ–å‚æ•°
3. LLMåæ€ - è§£é‡Šæœ‰æ•ˆå› å­çš„æŠ•èµ„é€»è¾‘

ä½¿ç”¨æ–¹æ³•:
    # å¿«é€Ÿæµ‹è¯• (1è½®LLM, å°‘é‡å› å­)
    python run_factor_mining.py --mode quick
    
    # æ ‡å‡†è¿è¡Œ (3è½®LLM, å®Œæ•´æµç¨‹)
    python run_factor_mining.py --mode standard
    
    # æ·±åº¦æŒ–æ˜ (5è½®LLM, å¤§è§„æ¨¡GP)
    python run_factor_mining.py --mode deep
    
    # è‡ªå®šä¹‰å‚æ•°
    python run_factor_mining.py --llm-rounds 3 --gp-generations 10 --batch-size 5

ç¯å¢ƒå˜é‡:
    DASHSCOPE_API_KEY: é˜¿é‡Œäº‘DashScope APIå¯†é’¥
    OPENAI_API_KEY: OpenAI APIå¯†é’¥ (å¯é€‰)
"""

from __future__ import annotations

import argparse
import json
import logging
import os
import sys
import time
import warnings
from dataclasses import dataclass, field, asdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Callable, Any, Tuple

import numpy as np
import pandas as pd

warnings.filterwarnings('ignore')

# è®¾ç½®é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent
sys.path.insert(0, str(PROJECT_ROOT.parent))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)


# ============================================================
# é…ç½®æ•°æ®ç±»
# ============================================================

@dataclass
class RunConfig:
    """è¿è¡Œé…ç½®"""
    # æ¨¡å¼
    mode: str = "standard"  # quick / standard / deep
    
    # LLMé…ç½®
    llm_provider: str = "dashscope"
    llm_model: str = "qwen-max"
    llm_rounds: int = 3
    llm_batch_size: int = 3
    
    # GPé…ç½®
    gp_population: int = 30
    gp_generations: int = 5
    
    # é˜ˆå€¼
    seed_threshold_ic: float = 0.005
    target_ic: float = 0.02
    max_turnover: float = 0.5
    
    # Qlibé…ç½®
    instruments: str = "csi300"
    train_start: str = "2018-01-01"
    train_end: str = "2021-12-31"
    test_start: str = "2022-01-01"
    test_end: str = "2023-12-31"
    
    # è¾“å‡º
    output_dir: str = "output/factors"
    save_results: bool = True
    
    @classmethod
    def from_mode(cls, mode: str) -> "RunConfig":
        """ä»é¢„è®¾æ¨¡å¼åˆ›å»ºé…ç½®"""
        if mode == "quick":
            return cls(
                mode="quick",
                llm_rounds=1,
                llm_batch_size=2,
                gp_population=10,
                gp_generations=2,
                seed_threshold_ic=0.003,
            )
        elif mode == "deep":
            return cls(
                mode="deep",
                llm_rounds=5,
                llm_batch_size=5,
                gp_population=50,
                gp_generations=10,
                seed_threshold_ic=0.008,
            )
        else:  # standard
            return cls(mode="standard")


# ============================================================
# æ ¸å¿ƒç»„ä»¶
# ============================================================

class FactorMiningSystem:
    """å› å­æŒ–æ˜ç³»ç»Ÿ - æ•´åˆæ‰€æœ‰ç»„ä»¶"""
    
    def __init__(self, config: RunConfig):
        self.config = config
        self.api_key: Optional[str] = None
        self.qlib_initialized: bool = False
        self._data_cache: Dict[str, Any] = {}
        
    def setup(self) -> bool:
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        logger.info("="*60)
        logger.info("     ğŸ§¬ Alpha Agent å› å­æŒ–æ˜ç³»ç»Ÿ")
        logger.info("="*60)
        logger.info(f"æ¨¡å¼: {self.config.mode}")
        logger.info(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info("="*60)
        
        # 1. æ£€æŸ¥API Key
        if not self._check_api_key():
            return False
        
        # 2. åˆå§‹åŒ–Qlib (å¯é€‰)
        if not self._init_qlib():
            logger.warning("âš ï¸ Qlibä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            self._create_mock_data()
        else:
            # 3. é¢„åŠ è½½æ•°æ®
            if not self._preload_data():
                logger.warning("âš ï¸ æ•°æ®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                self._create_mock_data()
        
        logger.info("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        return True
    
    def _check_api_key(self) -> bool:
        """æ£€æŸ¥API Key"""
        # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡
        self.api_key = os.environ.get("DASHSCOPE_API_KEY")
        
        if not self.api_key:
            # å°è¯•ä»é…ç½®æ–‡ä»¶è¯»å–
            try:
                import sys
                sys.path.insert(0, str(PROJECT_ROOT))
                from config.settings import LLMConfig
                llm_cfg = LLMConfig()
                self.api_key = llm_cfg.dashscope_api_key
            except Exception as e:
                logger.warning(f"é…ç½®è¯»å–å¤±è´¥: {e}")
        
        if not self.api_key:
            logger.error("âŒ æœªæ‰¾åˆ°API Key")
            logger.error("   è¯·è®¾ç½®ç¯å¢ƒå˜é‡: export DASHSCOPE_API_KEY=your-key")
            return False
        
        logger.info(f"âœ… API Key: {self.api_key[:8]}...")
        return True
    
    def _init_qlib(self) -> bool:
        """åˆå§‹åŒ–Qlib"""
        try:
            # ç¡®ä¿åœ¨æ­£ç¡®çš„å·¥ä½œç›®å½•
            os.chdir(PROJECT_ROOT)
            
            import qlib
            from qlib.config import REG_CN
            
            provider_uri = os.path.expanduser("~/.qlib/qlib_data/cn_data")
            
            if not os.path.exists(provider_uri):
                logger.error(f"âŒ Qlibæ•°æ®ä¸å­˜åœ¨: {provider_uri}")
                logger.error("   è¯·ä¸‹è½½: python -m qlib.run.get_data qlib_data --target_dir ~/.qlib/qlib_data")
                return False
            
            qlib.init(provider_uri=provider_uri, region=REG_CN)
            self.qlib_initialized = True
            logger.info(f"âœ… Qlibåˆå§‹åŒ–: {provider_uri}")
            return True
            
        except ImportError:
            logger.error("âŒ Qlibæœªå®‰è£…: pip install pyqlib")
            return False
        except Exception as e:
            import traceback
            logger.error(f"âŒ Qlibåˆå§‹åŒ–å¤±è´¥: {e}")
            logger.debug(traceback.format_exc())
            return False
    
    def _create_mock_data(self):
        """åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•"""
        logger.info("ğŸ“Š åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®...")
        
        n_days = 500
        n_stocks = 100
        
        dates = pd.date_range('2022-01-01', periods=n_days, freq='B')
        stocks = [f'SH60{i:04d}' for i in range(n_stocks)]
        
        index = pd.MultiIndex.from_product([stocks, dates], names=['instrument', 'datetime'])
        
        np.random.seed(42)
        base_price = 10 + np.random.randn(n_stocks, 1) * 5
        returns = np.random.randn(n_stocks, n_days) * 0.02
        prices = base_price * np.exp(returns.cumsum(axis=1))
        
        df = pd.DataFrame(index=index)
        df['close'] = prices.flatten()
        df['open'] = df['close'] * (1 + np.random.randn(len(df)) * 0.005)
        df['high'] = df[['close', 'open']].max(axis=1) * (1 + np.abs(np.random.randn(len(df))) * 0.01)
        df['low'] = df[['close', 'open']].min(axis=1) * (1 - np.abs(np.random.randn(len(df))) * 0.01)
        df['volume'] = np.abs(np.random.randn(len(df))) * 1e6 + 1e5
        df['adj_factor'] = 1.0
        
        # è®¡ç®—ç›®æ ‡æ”¶ç›Š
        future_return = df['close'].groupby(level=0).pct_change(5).shift(-5)
        
        self._data_cache['df'] = df
        self._data_cache['target'] = future_return
        
        logger.info(f"   æ¨¡æ‹Ÿæ•°æ®: {len(df):,} è¡Œ, {n_stocks} åªè‚¡ç¥¨, {n_days} å¤©")
    
    def _preload_data(self) -> bool:
        """é¢„åŠ è½½æ•°æ®åˆ°ç¼“å­˜"""
        try:
            from qlib.data import D
            
            logger.info("ğŸ“Š é¢„åŠ è½½Qlibæ•°æ®...")
            
            instruments = D.instruments(self.config.instruments)
            fields = ["$close", "$open", "$high", "$low", "$volume", "$factor"]
            
            df = D.features(
                instruments,
                fields,
                start_time=self.config.train_start,
                end_time=self.config.test_end,
                freq="day",
            )
            df.columns = ['close', 'open', 'high', 'low', 'volume', 'adj_factor']
            
            # è®¡ç®—æœªæ¥æ”¶ç›Šä½œä¸ºç›®æ ‡
            future_return = df['close'].groupby(level=0).pct_change(5).shift(-5)
            
            self._data_cache['df'] = df
            self._data_cache['target'] = future_return
            
            logger.info(f"   æ•°æ®é‡: {len(df):,} è¡Œ")
            logger.info(f"   æ—¶é—´èŒƒå›´: {df.index.get_level_values(1).min()} ~ {df.index.get_level_values(1).max()}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def create_llm_generator(self) -> Callable:
        """åˆ›å»ºLLMå› å­ç”Ÿæˆå™¨"""
        from dashscope import Generation
        from alpha_agent.prompt.composer import PromptComposer, TaskType
        
        composer = PromptComposer()
        api_key = self.api_key
        
        # å› å­ä¸»é¢˜åˆ—è¡¨
        themes = [
            "é‡ä»·åŠ¨é‡", "å‡å€¼å›å½’", "æ³¢åŠ¨ç‡å¼‚å¸¸", 
            "æˆäº¤é‡èƒŒç¦»", "è¶‹åŠ¿å¼ºåº¦", "ä»·æ ¼å½¢æ€",
            "èµ„é‡‘æµå‘", "æƒ…ç»ªæŒ‡æ ‡",
        ]
        
        # å†å²è®°å½•
        history = {"failures": [], "successes": []}
        
        def generator(context: dict) -> dict:
            """LLMå› å­ç”Ÿæˆå™¨"""
            round_idx = context.get('round', 0)
            existing_seeds = context.get('existing_seeds', [])
            best_ic = context.get('best_ic', 0)
            
            # é€‰æ‹©ä¸»é¢˜
            theme = themes[round_idx % len(themes)]
            
            # æ„å»ºRAGä¸Šä¸‹æ–‡
            rag_factors = []
            for i, seed in enumerate(existing_seeds[-3:]):
                if isinstance(seed, str) and len(seed) > 10:
                    rag_factors.append({
                        'name': f'Seed_{i}',
                        'ic': best_ic * (0.8 + i * 0.1),
                        'category': 'seed',
                        'source': 'evolution',
                        'logic': 'å‰è½®ç”Ÿæˆçš„ç§å­å› å­',
                        'code': seed[:200],
                    })
            
            # ç»„è£…Prompt
            composed = composer.for_generation(
                theme=theme,
                target_ic=self.config.target_ic,
                rag_factors=rag_factors,
                failures=history["failures"][-3:] if history["failures"] else None,
            )
            
            try:
                logger.info(f"  ğŸ“¤ è°ƒç”¨LLM (ä¸»é¢˜: {theme})...")
                
                response = Generation.call(
                    api_key=api_key,
                    model=self.config.llm_model,
                    messages=composed.to_messages(),
                    result_format="message",
                    temperature=0.7,
                )
                
                if response.status_code != 200:
                    raise RuntimeError(f"APIé”™è¯¯: {response.code} - {response.message}")
                
                content = response.output.choices[0].message.content
                logger.info(f"  ğŸ“¥ LLMå“åº”: {len(content)} å­—ç¬¦")
                
                # æå–ä»£ç 
                code = self._extract_code(content)
                name = self._extract_name(content) or f"LLM_{theme}_{int(time.time()) % 10000}"
                logic = self._extract_logic(content) or f"åŸºäº{theme}çš„å› å­"
                
                # è®°å½•æˆåŠŸ
                history["successes"].append({"theme": theme, "name": name})
                
                return {"name": name, "code": code, "logic": logic}
                
            except Exception as e:
                # è®°å½•å¤±è´¥
                history["failures"].append({
                    "factor_name": f"Round{round_idx}",
                    "problem": str(e)[:100],
                    "diagnosis": "APIè°ƒç”¨æˆ–ä»£ç è§£æå¤±è´¥",
                    "suggestion": "æ£€æŸ¥ç½‘ç»œæˆ–ç®€åŒ–å› å­é€»è¾‘",
                })
                logger.warning(f"  âŒ LLMç”Ÿæˆå¤±è´¥: {e}")
                raise
        
        return generator
    
    def create_evaluator(self) -> Callable:
        """åˆ›å»ºå› å­è¯„ä¼°å™¨"""
        from alpha_agent.core.sandbox import Sandbox
        from alpha_agent.core.evaluator import FactorEvaluator
        
        sandbox = Sandbox(timeout_seconds=30)
        core_evaluator = FactorEvaluator()
        
        df = self._data_cache['df']
        target = self._data_cache['target']
        
        def evaluator(factor_code: str, full_backtest: bool = False) -> dict:
            """è¯„ä¼°å› å­"""
            try:
                # 1. æ²™ç®±æ‰§è¡Œ
                factor_values, error = sandbox.execute(factor_code, df)
                
                if error:
                    raise RuntimeError(f"æ‰§è¡Œå¤±è´¥: {error[:100]}")
                
                if factor_values is None or len(factor_values) == 0:
                    raise RuntimeError("å› å­å€¼ä¸ºç©º")
                
                # 2. å¯¹é½æ•°æ®
                aligned = pd.concat([factor_values, target], axis=1)
                aligned.columns = ['factor', 'return']
                aligned = aligned.dropna()
                
                if len(aligned) < 100:
                    raise RuntimeError(f"æœ‰æ•ˆæ•°æ®ä¸è¶³: {len(aligned)}")
                
                # 3. ä½¿ç”¨CoreEvaluatorè®¡ç®—æŒ‡æ ‡
                result = core_evaluator.evaluate(
                    factor=aligned['factor'],
                    target=aligned['return'],
                )
                
                logger.info(f"    IC={result.ic:.4f}, ICIR={result.icir:.2f}, çŠ¶æ€={result.status.value}")
                
                return {
                    'ic': abs(result.ic),
                    'icir': abs(result.icir),
                    'rank_ic': abs(result.rank_ic),
                    'rank_icir': abs(getattr(result, 'rank_icir', result.icir)),
                    'ann_return': getattr(result, 'long_short_return', 0) * 252,
                    'information_ratio': abs(result.icir),
                    'sharpe': abs(result.icir) * 1.5,
                    'max_drawdown': 0.15,
                    'turnover': 0.3,
                }
                
            except Exception as e:
                logger.warning(f"    è¯„ä¼°å¤±è´¥: {e}")
                raise
        
        return evaluator
    
    def run(self) -> List[Any]:
        """è¿è¡Œå› å­æŒ–æ˜"""
        from alpha_agent.evolution.hybrid_engine import HybridEvolutionEngine, HybridConfig
        
        # åˆ›å»ºHybridConfig
        hybrid_config = HybridConfig(
            llm_batch_size=self.config.llm_batch_size,
            llm_rounds=self.config.llm_rounds,
            seed_threshold_ic=self.config.seed_threshold_ic,
            seed_pool_size=20,
            gp_population=self.config.gp_population,
            gp_generations=self.config.gp_generations,
            gp_elite_rate=0.2,
            reflect_top_k=5,
            max_turnover=self.config.max_turnover,
            target_ic=self.config.target_ic,
        )
        
        # æ‰“å°é…ç½®
        logger.info("\nğŸ“‹ è¿è¡Œé…ç½®:")
        logger.info(f"   LLMè½®æ•°: {hybrid_config.llm_rounds}")
        logger.info(f"   æ¯è½®ç”Ÿæˆ: {hybrid_config.llm_batch_size}")
        logger.info(f"   GPç§ç¾¤: {hybrid_config.gp_population}")
        logger.info(f"   GPä»£æ•°: {hybrid_config.gp_generations}")
        logger.info(f"   ICé˜ˆå€¼: {hybrid_config.seed_threshold_ic}")
        
        # åˆ›å»ºå¼•æ“
        engine = HybridEvolutionEngine(
            config=hybrid_config,
            llm_generator=self.create_llm_generator(),
            evaluator=self.create_evaluator(),
        )
        
        # è¿è¡Œè¿›åŒ–
        logger.info("\n" + "="*60)
        logger.info("ğŸš€ å¼€å§‹æ··åˆè¿›åŒ–")
        logger.info("="*60)
        
        start_time = time.time()
        
        try:
            best_factors = engine.evolve()
            elapsed = time.time() - start_time
            
            # è¾“å‡ºç»“æœ
            self._print_results(best_factors, engine, elapsed)
            
            # ä¿å­˜ç»“æœ
            if self.config.save_results and best_factors:
                self._save_results(best_factors)
            
            return best_factors
            
        except KeyboardInterrupt:
            logger.warning("\nâš ï¸ ç”¨æˆ·ä¸­æ–­")
            return []
        except Exception as e:
            logger.error(f"âŒ è¿è¡Œå¤±è´¥: {e}", exc_info=True)
            raise
    
    def _print_results(self, factors: List, engine: Any, elapsed: float):
        """æ‰“å°ç»“æœ"""
        logger.info("\n" + "="*60)
        logger.info("                 ğŸ“ˆ å› å­æŒ–æ˜ç»“æœ")
        logger.info("="*60)
        
        if factors:
            logger.info(f"\nâœ… æˆåŠŸç”Ÿæˆ {len(factors)} ä¸ªæœ‰æ•ˆå› å­:\n")
            
            for i, f in enumerate(factors, 1):
                logger.info(f"ã€å› å­ {i}ã€‘{f.name}")
                logger.info(f"   æ¥æº: {f.source}")
                logger.info(f"   IC: {f.ic:.4f} [{f.ic_grade}]")
                logger.info(f"   ICIR: {f.icir:.2f}")
                logger.info(f"   Rank IC: {f.rank_ic:.4f}")
                if f.logic:
                    logger.info(f"   é€»è¾‘: {f.logic[:80]}...")
                logger.info("")
        else:
            logger.info("\nâš ï¸ æœªç”Ÿæˆæœ‰æ•ˆå› å­")
        
        # ç»Ÿè®¡
        logger.info("-"*60)
        logger.info(f"ğŸ“Š ç»Ÿè®¡:")
        logger.info(f"   ç§å­åº“: {len(engine.seed_pool)}")
        logger.info(f"   ç²¾è‹±æ± : {len(engine.elite_pool)}")
        logger.info(f"   æœ€ä¼˜IC: {engine.best_ic:.4f}")
        logger.info(f"   æ€»è€—æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ")
    
    def _save_results(self, factors: List):
        """ä¿å­˜ç»“æœ"""
        output_dir = PROJECT_ROOT / self.config.output_dir
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = output_dir / f"factors_{self.config.mode}_{timestamp}.json"
        
        data = []
        for f in factors:
            data.append({
                "id": f.id,
                "name": f.name,
                "code": f.code,
                "source": f.source,
                "ic": f.ic,
                "icir": f.icir,
                "rank_ic": f.rank_ic,
                "sharpe": f.sharpe,
                "ic_grade": f.ic_grade,
                "logic": f.logic,
                "created_at": f.created_at,
            })
        
        with open(output_file, 'w', encoding='utf-8') as fp:
            json.dump(data, fp, ensure_ascii=False, indent=2)
        
        logger.info(f"\nğŸ“ ç»“æœå·²ä¿å­˜: {output_file}")
    
    # ============================================================
    # è¾…åŠ©æ–¹æ³•
    # ============================================================
    
    def _extract_code(self, content: str) -> str:
        """ä»LLMå“åº”ä¸­æå–ä»£ç """
        import re
        
        def clean_imports(code: str) -> str:
            lines = code.split('\n')
            cleaned = []
            for line in lines:
                stripped = line.strip()
                if stripped.startswith('import ') or stripped.startswith('from '):
                    continue
                cleaned.append(line)
            return '\n'.join(cleaned)
        
        # ä»```pythonä»£ç å—æå–
        if "```python" in content:
            match = re.search(r'```python\s*\n(.*?)\n```', content, re.DOTALL)
            if match:
                code = match.group(1).strip()
                if 'def compute_alpha' in code:
                    return clean_imports(code)
                elif 'df[' in code:
                    expr = code.strip()
                    if '=' in expr and not expr.startswith('def'):
                        expr = expr.split('=', 1)[1].strip()
                    return f'def compute_alpha(df):\n    """LLMç”Ÿæˆçš„å› å­"""\n    return {expr}'
        
        # ä»```ä»£ç å—æå–
        if "```" in content:
            parts = content.split("```")
            for part in parts[1::2]:
                part = part.replace("python", "").strip()
                if 'def compute_alpha' in part:
                    return clean_imports(part)
        
        # æŸ¥æ‰¾def compute_alpha
        if 'def compute_alpha' in content:
            start = content.find('def compute_alpha')
            lines = content[start:].split('\n')
            code_lines = []
            for i, line in enumerate(lines):
                if i == 0 or line.startswith(' ') or line.startswith('\t') or not line.strip():
                    code_lines.append(line)
                elif line.strip() and not line.startswith(' '):
                    break
            return clean_imports('\n'.join(code_lines).strip())
        
        # æŸ¥æ‰¾dfè¡¨è¾¾å¼
        for line in content.split('\n'):
            line = line.strip()
            if 'df[' in line and not line.startswith('#'):
                expr = line
                if '=' in expr:
                    expr = expr.split('=', 1)[1].strip()
                return f'def compute_alpha(df):\n    """LLMç”Ÿæˆçš„å› å­"""\n    return {expr}'
        
        # é»˜è®¤å› å­
        return '''def compute_alpha(df):
    """é»˜è®¤åŠ¨é‡å› å­"""
    return df["close"].pct_change(5).fillna(0)'''
    
    def _extract_name(self, content: str) -> Optional[str]:
        """æå–å› å­åç§°"""
        import re
        match = re.search(r'å› å­åç§°[ï¼š:]\s*(.+?)[\n\r]', content)
        if match:
            return match.group(1).strip()[:50]
        return None
    
    def _extract_logic(self, content: str) -> Optional[str]:
        """æå–å› å­é€»è¾‘"""
        import re
        match = re.search(r'å› å­é€»è¾‘[ï¼š:]\s*(.+?)[\n\r]', content)
        if match:
            return match.group(1).strip()[:200]
        return None


# ============================================================
# å‘½ä»¤è¡Œæ¥å£
# ============================================================

def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="Alpha Agent å› å­æŒ–æ˜ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python run_factor_mining.py --mode quick          # å¿«é€Ÿæµ‹è¯•
  python run_factor_mining.py --mode standard       # æ ‡å‡†è¿è¡Œ
  python run_factor_mining.py --mode deep           # æ·±åº¦æŒ–æ˜
  python run_factor_mining.py --llm-rounds 5        # è‡ªå®šä¹‰è½®æ•°
        """
    )
    
    parser.add_argument(
        "--mode", "-m",
        choices=["quick", "standard", "deep"],
        default="standard",
        help="è¿è¡Œæ¨¡å¼ (é»˜è®¤: standard)"
    )
    
    parser.add_argument(
        "--llm-rounds", "-r",
        type=int,
        help="LLMæ¢ç´¢è½®æ•°"
    )
    
    parser.add_argument(
        "--batch-size", "-b",
        type=int,
        help="æ¯è½®ç”Ÿæˆå› å­æ•°"
    )
    
    parser.add_argument(
        "--gp-generations", "-g",
        type=int,
        help="GPè¿­ä»£ä»£æ•°"
    )
    
    parser.add_argument(
        "--instruments", "-i",
        default="csi300",
        help="è‚¡ç¥¨æ±  (é»˜è®¤: csi300)"
    )
    
    parser.add_argument(
        "--no-save",
        action="store_true",
        help="ä¸ä¿å­˜ç»“æœ"
    )
    
    parser.add_argument(
        "--yes", "-y",
        action="store_true",
        help="è·³è¿‡ç¡®è®¤æç¤º"
    )
    
    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # åˆ›å»ºé…ç½®
    config = RunConfig.from_mode(args.mode)
    
    # è¦†ç›–å‚æ•°
    if args.llm_rounds:
        config.llm_rounds = args.llm_rounds
    if args.batch_size:
        config.llm_batch_size = args.batch_size
    if args.gp_generations:
        config.gp_generations = args.gp_generations
    if args.instruments:
        config.instruments = args.instruments
    if args.no_save:
        config.save_results = False
    
    # ç¡®è®¤è¿è¡Œ
    if not args.yes:
        print("\n" + "="*60)
        print("     âš ï¸  Alpha Agent å› å­æŒ–æ˜ç³»ç»Ÿ")
        print("="*60)
        print(f"\næ¨¡å¼: {config.mode}")
        print(f"LLMè½®æ•°: {config.llm_rounds}")
        print(f"æ¯è½®ç”Ÿæˆ: {config.llm_batch_size}")
        print(f"é¢„è®¡æ—¶é—´: {config.llm_rounds * config.llm_batch_size * 2 + config.gp_generations * 2} åˆ†é’Ÿ")
        print("\næ³¨æ„: ä¼šäº§ç”Ÿå®é™…APIè°ƒç”¨è´¹ç”¨")
        print("="*60)
        
        confirm = input("\nç¡®è®¤è¿è¡Œ? (y/n): ").strip().lower()
        if confirm != 'y':
            print("å·²å–æ¶ˆ")
            return 0
    
    # åˆ›å»ºç³»ç»Ÿå¹¶è¿è¡Œ
    system = FactorMiningSystem(config)
    
    if not system.setup():
        return 1
    
    try:
        results = system.run()
        
        if results:
            logger.info("\n" + "="*60)
            logger.info("                 âœ… å› å­æŒ–æ˜å®Œæˆ")
            logger.info("="*60)
            return 0
        else:
            logger.warning("\nâš ï¸ æœªç”Ÿæˆæœ‰æ•ˆå› å­")
            return 1
            
    except Exception as e:
        logger.error(f"\nâŒ è¿è¡Œå¤±è´¥: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
