"""
ç‰¹å¾é€‰æ‹©ä¸è§£é‡Šæ¨¡å— (Feature Selection & XAI)

åŠŸèƒ½:
1. ICåˆ†æ - ä¿¡æ¯ç³»æ•°è®¡ç®—
2. å…±çº¿æ€§åˆ†æ - ç›¸å…³æ€§çŸ©é˜µä¸VIF
3. ç‰¹å¾é‡è¦æ€§ - SHAP/Permutation Importance
4. è‡ªåŠ¨ç‰¹å¾ç­›é€‰ - ç»¼åˆè¯„åˆ†è¿‡æ»¤å™ªå£°ç‰¹å¾
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from pathlib import Path
import warnings
import json
from datetime import datetime

# å¯é€‰ä¾èµ–
try:
    import shap
    SHAP_AVAILABLE = True
except ImportError:
    SHAP_AVAILABLE = False

try:
    import lightgbm as lgb
    LGB_AVAILABLE = True
except ImportError:
    LGB_AVAILABLE = False

try:
    from sklearn.inspection import permutation_importance
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.linear_model import LassoCV
    from sklearn.preprocessing import StandardScaler
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

from .config import OUTPUT_DIR


@dataclass
class FeatureReport:
    """å•ä¸ªç‰¹å¾çš„è§£é‡Šæ€§æŠ¥å‘Š"""
    name: str
    ic: float
    ic_ir: float  # ICä¿¡æ¯æ¯”ç‡
    abs_ic: float
    importance_shap: float
    importance_perm: float
    importance_lgb: float
    correlation_max: float  # ä¸å…¶ä»–ç‰¹å¾çš„æœ€å¤§ç›¸å…³æ€§
    vif: float  # æ–¹å·®è†¨èƒ€å› å­
    stability: float  # ICç¨³å®šæ€§ (æ»šåŠ¨ICæ ‡å‡†å·®)
    final_score: float  # ç»¼åˆè¯„åˆ†
    recommendation: str  # ä¿ç•™/å‰”é™¤/å¾…å®š


class FeatureSelector:
    """ç‰¹å¾é€‰æ‹©ä¸è§£é‡Šå™¨"""
    
    def __init__(
        self,
        ic_threshold: float = 0.02,
        correlation_threshold: float = 0.85,
        vif_threshold: float = 10.0,
        min_importance: float = 0.01,
        top_k: int = None,
    ):
        """
        åˆå§‹åŒ–ç‰¹å¾é€‰æ‹©å™¨
        
        å‚æ•°:
            ic_threshold: ICé˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„ç‰¹å¾è¢«å‰”é™¤
            correlation_threshold: å…±çº¿æ€§é˜ˆå€¼
            vif_threshold: VIFé˜ˆå€¼
            min_importance: æœ€å°é‡è¦æ€§é˜ˆå€¼
            top_k: ä¿ç•™top Kä¸ªç‰¹å¾ (Noneè¡¨ç¤ºä¸é™åˆ¶)
        """
        self.ic_threshold = ic_threshold
        self.correlation_threshold = correlation_threshold
        self.vif_threshold = vif_threshold
        self.min_importance = min_importance
        self.top_k = top_k
        
        self.feature_reports: Dict[str, FeatureReport] = {}
        self.correlation_matrix: pd.DataFrame = None
        self.selected_features: List[str] = []
    
    def fit(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        feature_names: List[str] = None,
    ) -> 'FeatureSelector':
        """
        æ‹Ÿåˆç‰¹å¾é€‰æ‹©å™¨
        
        å‚æ•°:
            X: ç‰¹å¾çŸ©é˜µ
            y: ç›®æ ‡å˜é‡
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
        """
        if feature_names is None:
            feature_names = list(X.columns)
        
        print("\n" + "="*70)
        print("ã€ç‰¹å¾é€‰æ‹©ä¸è§£é‡Šåˆ†æã€‘")
        print("="*70)
        
        # 1. è®¡ç®—IC
        print("\nğŸ“Š Step 1: è®¡ç®—ä¿¡æ¯ç³»æ•° (IC)...")
        ic_results = self._compute_ic(X[feature_names], y)
        
        # 2. è®¡ç®—å…±çº¿æ€§
        print("ğŸ“Š Step 2: è®¡ç®—å…±çº¿æ€§çŸ©é˜µ...")
        self.correlation_matrix = self._compute_correlation(X[feature_names])
        vif_results = self._compute_vif(X[feature_names])
        
        # 3. è®¡ç®—ç‰¹å¾é‡è¦æ€§
        print("ğŸ“Š Step 3: è®¡ç®—ç‰¹å¾é‡è¦æ€§ (SHAP/Permutation/LGB)...")
        importance_results = self._compute_importance(X[feature_names], y)
        
        # 4. ç”Ÿæˆç‰¹å¾æŠ¥å‘Š
        print("ğŸ“Š Step 4: ç”Ÿæˆç‰¹å¾æŠ¥å‘Š...")
        self._generate_reports(
            feature_names, ic_results, vif_results, importance_results
        )
        
        # 5. ç‰¹å¾ç­›é€‰
        print("ğŸ“Š Step 5: ç‰¹å¾ç­›é€‰...")
        self._select_features()
        
        return self
    
    def _compute_ic(
        self, 
        X: pd.DataFrame, 
        y: pd.Series,
        rolling_window: int = 60
    ) -> Dict[str, Dict]:
        """è®¡ç®—ICåŠç›¸å…³æŒ‡æ ‡"""
        results = {}
        
        for col in X.columns:
            valid_mask = X[col].notna() & y.notna()
            if valid_mask.sum() < 30:
                results[col] = {'ic': 0, 'ic_ir': 0, 'stability': 0}
                continue
            
            x_valid = X.loc[valid_mask, col]
            y_valid = y[valid_mask]
            
            # æ•´ä½“IC
            ic = x_valid.corr(y_valid, method='spearman')
            
            # æ»šåŠ¨IC
            rolling_ic = []
            for i in range(rolling_window, len(x_valid)):
                window_x = x_valid.iloc[i-rolling_window:i]
                window_y = y_valid.iloc[i-rolling_window:i]
                if len(window_x) >= 20:
                    rolling_ic.append(window_x.corr(window_y, method='spearman'))
            
            rolling_ic = pd.Series(rolling_ic)
            ic_mean = rolling_ic.mean() if len(rolling_ic) > 0 else ic
            ic_std = rolling_ic.std() if len(rolling_ic) > 0 else 0.1
            ic_ir = ic_mean / (ic_std + 1e-8)  # ICä¿¡æ¯æ¯”ç‡
            stability = 1 - ic_std  # ç¨³å®šæ€§
            
            results[col] = {
                'ic': ic if not np.isnan(ic) else 0,
                'ic_ir': ic_ir if not np.isnan(ic_ir) else 0,
                'stability': stability if not np.isnan(stability) else 0,
            }
        
        return results
    
    def _compute_correlation(self, X: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ"""
        return X.corr(method='spearman')
    
    def _compute_vif(self, X: pd.DataFrame) -> Dict[str, float]:
        """è®¡ç®—æ–¹å·®è†¨èƒ€å› å­ (VIF)"""
        if not SKLEARN_AVAILABLE:
            return {col: 1.0 for col in X.columns}
        
        vif_results = {}
        X_clean = X.dropna()
        
        if len(X_clean) < 100:
            return {col: 1.0 for col in X.columns}
        
        # æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X_scaled = pd.DataFrame(
            scaler.fit_transform(X_clean),
            columns=X_clean.columns,
            index=X_clean.index
        )
        
        for col in X.columns:
            try:
                other_cols = [c for c in X.columns if c != col]
                if len(other_cols) == 0:
                    vif_results[col] = 1.0
                    continue
                
                # ç”¨å…¶ä»–ç‰¹å¾é¢„æµ‹å½“å‰ç‰¹å¾
                y_col = X_scaled[col]
                X_other = X_scaled[other_cols]
                
                # ç®€åŒ–è®¡ç®—: ä½¿ç”¨RÂ²
                from sklearn.linear_model import LinearRegression
                model = LinearRegression()
                model.fit(X_other, y_col)
                r_squared = model.score(X_other, y_col)
                
                vif = 1 / (1 - r_squared + 1e-8)
                vif_results[col] = min(vif, 100)  # é™åˆ¶æœ€å¤§å€¼
            except Exception:
                vif_results[col] = 1.0
        
        return vif_results
    
    def _compute_importance(
        self, 
        X: pd.DataFrame, 
        y: pd.Series
    ) -> Dict[str, Dict]:
        """è®¡ç®—å¤šç§ç‰¹å¾é‡è¦æ€§"""
        results = {col: {'shap': 0, 'perm': 0, 'lgb': 0} for col in X.columns}
        
        # å‡†å¤‡æ•°æ®
        valid_mask = X.notna().all(axis=1) & y.notna()
        X_clean = X[valid_mask].copy()
        y_clean = y[valid_mask].copy()
        
        if len(X_clean) < 100:
            return results
        
        # å¡«å……å‰©ä½™NaN
        X_clean = X_clean.fillna(X_clean.median())
        
        # 1. LightGBM ç‰¹å¾é‡è¦æ€§
        if LGB_AVAILABLE:
            try:
                model = lgb.LGBMRegressor(
                    n_estimators=100,
                    max_depth=5,
                    learning_rate=0.1,
                    verbose=-1,
                    n_jobs=-1
                )
                model.fit(X_clean, y_clean)
                importance = model.feature_importances_
                importance = importance / (importance.sum() + 1e-8)
                
                for i, col in enumerate(X_clean.columns):
                    results[col]['lgb'] = importance[i]
            except Exception as e:
                print(f"  LGB importance failed: {e}")
        
        # 2. Permutation Importance
        if SKLEARN_AVAILABLE:
            try:
                # ä½¿ç”¨ç®€å•RF
                rf = RandomForestRegressor(n_estimators=50, max_depth=5, n_jobs=-1)
                rf.fit(X_clean, y_clean)
                
                perm_result = permutation_importance(
                    rf, X_clean, y_clean, 
                    n_repeats=5, random_state=42, n_jobs=-1
                )
                importance = perm_result.importances_mean
                importance = np.maximum(importance, 0)
                importance = importance / (importance.sum() + 1e-8)
                
                for i, col in enumerate(X_clean.columns):
                    results[col]['perm'] = importance[i]
            except Exception as e:
                print(f"  Permutation importance failed: {e}")
        
        # 3. SHAP (ä»…åœ¨ç‰¹å¾æ•°é‡åˆç†æ—¶)
        if SHAP_AVAILABLE and LGB_AVAILABLE and len(X_clean.columns) <= 50:
            try:
                model = lgb.LGBMRegressor(n_estimators=50, max_depth=4, verbose=-1)
                model.fit(X_clean, y_clean)
                
                # é‡‡æ ·ä»¥åŠ é€Ÿ
                sample_size = min(500, len(X_clean))
                X_sample = X_clean.sample(sample_size, random_state=42)
                
                explainer = shap.TreeExplainer(model)
                shap_values = explainer.shap_values(X_sample)
                
                importance = np.abs(shap_values).mean(axis=0)
                importance = importance / (importance.sum() + 1e-8)
                
                for i, col in enumerate(X_clean.columns):
                    results[col]['shap'] = importance[i]
            except Exception as e:
                print(f"  SHAP failed: {e}")
        
        return results
    
    def _generate_reports(
        self,
        feature_names: List[str],
        ic_results: Dict,
        vif_results: Dict,
        importance_results: Dict,
    ):
        """ç”Ÿæˆç‰¹å¾æŠ¥å‘Š"""
        for name in feature_names:
            ic_data = ic_results.get(name, {})
            imp_data = importance_results.get(name, {})
            
            ic = ic_data.get('ic', 0)
            ic_ir = ic_data.get('ic_ir', 0)
            stability = ic_data.get('stability', 0)
            
            # è®¡ç®—ä¸å…¶ä»–ç‰¹å¾çš„æœ€å¤§ç›¸å…³æ€§
            if self.correlation_matrix is not None and name in self.correlation_matrix.columns:
                corr_row = self.correlation_matrix[name].drop(name, errors='ignore')
                max_corr = corr_row.abs().max() if len(corr_row) > 0 else 0
            else:
                max_corr = 0
            
            # ç»¼åˆè¯„åˆ†
            score = self._compute_final_score(
                ic=ic,
                ic_ir=ic_ir,
                stability=stability,
                importance_shap=imp_data.get('shap', 0),
                importance_lgb=imp_data.get('lgb', 0),
                max_corr=max_corr,
                vif=vif_results.get(name, 1)
            )
            
            # æ¨è
            recommendation = self._get_recommendation(
                ic, max_corr, vif_results.get(name, 1), score
            )
            
            self.feature_reports[name] = FeatureReport(
                name=name,
                ic=ic,
                ic_ir=ic_ir,
                abs_ic=abs(ic),
                importance_shap=imp_data.get('shap', 0),
                importance_perm=imp_data.get('perm', 0),
                importance_lgb=imp_data.get('lgb', 0),
                correlation_max=max_corr,
                vif=vif_results.get(name, 1),
                stability=stability,
                final_score=score,
                recommendation=recommendation
            )
    
    def _compute_final_score(
        self,
        ic: float,
        ic_ir: float,
        stability: float,
        importance_shap: float,
        importance_lgb: float,
        max_corr: float,
        vif: float,
    ) -> float:
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        # æƒé‡é…ç½®
        weights = {
            'ic': 0.25,
            'ic_ir': 0.15,
            'stability': 0.10,
            'importance': 0.30,
            'independence': 0.20,
        }
        
        # ICåˆ†æ•° (ç»å¯¹å€¼)
        ic_score = min(abs(ic) / 0.1, 1.0)
        
        # IC_IRåˆ†æ•°
        ic_ir_score = min(abs(ic_ir) / 1.0, 1.0)
        
        # ç¨³å®šæ€§åˆ†æ•°
        stability_score = max(0, min(stability, 1.0))
        
        # é‡è¦æ€§åˆ†æ•° (å–å¤šç§æ–¹æ³•çš„å¹³å‡)
        importance_score = (importance_shap + importance_lgb) / 2 * 10  # æ”¾å¤§
        importance_score = min(importance_score, 1.0)
        
        # ç‹¬ç«‹æ€§åˆ†æ•° (ç›¸å…³æ€§å’ŒVIF)
        corr_penalty = max(0, 1 - max_corr)
        vif_penalty = max(0, 1 - (vif - 1) / 10)
        independence_score = (corr_penalty + vif_penalty) / 2
        
        # ç»¼åˆåˆ†æ•°
        final_score = (
            weights['ic'] * ic_score +
            weights['ic_ir'] * ic_ir_score +
            weights['stability'] * stability_score +
            weights['importance'] * importance_score +
            weights['independence'] * independence_score
        )
        
        return final_score
    
    def _get_recommendation(
        self,
        ic: float,
        max_corr: float,
        vif: float,
        score: float,
    ) -> str:
        """ç”Ÿæˆæ¨è"""
        if abs(ic) < self.ic_threshold:
            return "å‰”é™¤ (ICè¿‡ä½)"
        if max_corr > self.correlation_threshold:
            return "å¾…å®š (é«˜å…±çº¿æ€§)"
        if vif > self.vif_threshold:
            return "å¾…å®š (VIFè¿‡é«˜)"
        if score > 0.5:
            return "ä¿ç•™ (ä¼˜è´¨ç‰¹å¾)"
        if score > 0.3:
            return "ä¿ç•™ (å¯ç”¨ç‰¹å¾)"
        return "å¾…å®š (è¾¹ç¼˜ç‰¹å¾)"
    
    def _select_features(self):
        """æ‰§è¡Œç‰¹å¾ç­›é€‰"""
        # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
        sorted_reports = sorted(
            self.feature_reports.values(),
            key=lambda x: x.final_score,
            reverse=True
        )
        
        selected = []
        selected_set = set()
        
        for report in sorted_reports:
            # è·³è¿‡æ˜ç¡®å‰”é™¤çš„
            if "å‰”é™¤" in report.recommendation:
                continue
            
            # æ£€æŸ¥ä¸å·²é€‰ç‰¹å¾çš„ç›¸å…³æ€§
            too_correlated = False
            if self.correlation_matrix is not None:
                for selected_name in selected_set:
                    if selected_name in self.correlation_matrix.columns:
                        corr = abs(self.correlation_matrix.loc[report.name, selected_name])
                        if corr > self.correlation_threshold:
                            too_correlated = True
                            break
            
            if too_correlated:
                continue
            
            selected.append(report.name)
            selected_set.add(report.name)
            
            # top_ké™åˆ¶
            if self.top_k and len(selected) >= self.top_k:
                break
        
        self.selected_features = selected
        
        print(f"\nâœ… ç­›é€‰ç»“æœ: {len(selected)}/{len(self.feature_reports)} ä¸ªç‰¹å¾")
    
    def get_selected_features(self) -> List[str]:
        """è·å–ç­›é€‰åçš„ç‰¹å¾åˆ—è¡¨"""
        return self.selected_features
    
    def get_feature_report(self, name: str) -> Optional[FeatureReport]:
        """è·å–å•ä¸ªç‰¹å¾çš„æŠ¥å‘Š"""
        return self.feature_reports.get(name)
    
    def get_all_reports(self) -> pd.DataFrame:
        """è·å–æ‰€æœ‰ç‰¹å¾æŠ¥å‘Šçš„DataFrame"""
        records = []
        for report in self.feature_reports.values():
            records.append({
                'ç‰¹å¾': report.name,
                'IC': f"{report.ic:.4f}",
                'IC_IR': f"{report.ic_ir:.2f}",
                '|IC|': f"{report.abs_ic:.4f}",
                'SHAP': f"{report.importance_shap:.3f}",
                'Perm': f"{report.importance_perm:.3f}",
                'LGB': f"{report.importance_lgb:.3f}",
                'æœ€å¤§ç›¸å…³': f"{report.correlation_max:.2f}",
                'VIF': f"{report.vif:.1f}",
                'ç¨³å®šæ€§': f"{report.stability:.2f}",
                'ç»¼åˆåˆ†': f"{report.final_score:.3f}",
                'æ¨è': report.recommendation,
            })
        
        df = pd.DataFrame(records)
        df = df.sort_values('ç»¼åˆåˆ†', ascending=False)
        return df
    
    def print_summary(self, top_n: int = 20):
        """æ‰“å°æ‘˜è¦"""
        print("\n" + "="*70)
        print("ã€ç‰¹å¾ç­›é€‰ç»“æœæ‘˜è¦ã€‘")
        print("="*70)
        
        df = self.get_all_reports()
        
        print(f"\nğŸ“Š æ€»ç‰¹å¾æ•°: {len(df)}")
        print(f"ğŸ“Š ä¿ç•™ç‰¹å¾: {len(self.selected_features)}")
        print(f"ğŸ“Š å‰”é™¤ç‰¹å¾: {len(df) - len(self.selected_features)}")
        
        print(f"\nğŸ† Top {top_n} ç‰¹å¾:")
        print("-"*70)
        print(df.head(top_n).to_string(index=False))
        
        print(f"\nâœ… æœ€ç»ˆé€‰æ‹©çš„ç‰¹å¾:")
        for i, name in enumerate(self.selected_features[:20], 1):
            report = self.feature_reports[name]
            print(f"  {i:2d}. {name}: IC={report.ic:.4f}, Score={report.final_score:.3f}")
        
        if len(self.selected_features) > 20:
            print(f"  ... å…± {len(self.selected_features)} ä¸ª")
    
    def save_report(self, path: Path = None):
        """ä¿å­˜å®Œæ•´æŠ¥å‘Š"""
        if path is None:
            path = OUTPUT_DIR / 'feature_selection_report.json'
        
        report_data = {
            'timestamp': datetime.now().isoformat(),
            'config': {
                'ic_threshold': self.ic_threshold,
                'correlation_threshold': self.correlation_threshold,
                'vif_threshold': self.vif_threshold,
                'top_k': self.top_k,
            },
            'summary': {
                'total_features': len(self.feature_reports),
                'selected_features': len(self.selected_features),
            },
            'selected_features': self.selected_features,
            'feature_reports': {
                name: {
                    'ic': report.ic,
                    'ic_ir': report.ic_ir,
                    'importance_shap': report.importance_shap,
                    'importance_lgb': report.importance_lgb,
                    'correlation_max': report.correlation_max,
                    'vif': report.vif,
                    'final_score': report.final_score,
                    'recommendation': report.recommendation,
                }
                for name, report in self.feature_reports.items()
            }
        }
        
        with open(path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        # åŒæ—¶ä¿å­˜CSV
        csv_path = path.with_suffix('.csv')
        self.get_all_reports().to_csv(csv_path, index=False)
        
        print(f"\nğŸ“ æŠ¥å‘Šå·²ä¿å­˜: {path}")
        print(f"ğŸ“ CSVå·²ä¿å­˜: {csv_path}")


def select_features(
    X: pd.DataFrame,
    y: pd.Series,
    ic_threshold: float = 0.02,
    correlation_threshold: float = 0.85,
    top_k: int = None,
) -> Tuple[List[str], pd.DataFrame]:
    """
    ä¾¿æ·å‡½æ•°: ç‰¹å¾é€‰æ‹©
    
    è¿”å›:
        selected_features: ç­›é€‰åçš„ç‰¹å¾åˆ—è¡¨
        report_df: ç‰¹å¾æŠ¥å‘ŠDataFrame
    """
    selector = FeatureSelector(
        ic_threshold=ic_threshold,
        correlation_threshold=correlation_threshold,
        top_k=top_k,
    )
    selector.fit(X, y)
    selector.print_summary()
    selector.save_report()
    
    return selector.get_selected_features(), selector.get_all_reports()
