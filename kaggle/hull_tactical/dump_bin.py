"""
Hull Tactical æ•°æ®é¢„å¤„ç†è„šæœ¬
å°† Kaggle CSV è½¬æ¢ä¸º Qlib äºŒè¿›åˆ¶æ ¼å¼
"""
import os
import sys
import shutil
from pathlib import Path

import pandas as pd
import numpy as np


# ============ é…ç½® ============
BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / "data"
QLIB_DATA_DIR = Path.home() / ".qlib/qlib_data/hull_data"

TRAIN_CSV = DATA_DIR / "train.csv"
TEST_CSV = DATA_DIR / "test.csv"

# ç‰¹å¾åˆ—å‰ç¼€ (æŽ’é™¤ date_id å’Œ target åˆ—)
FEATURE_PREFIXES = ["D", "E", "I", "M", "P", "S", "V"]
TARGET_COL = "market_forward_excess_returns"


def get_feature_columns(df: pd.DataFrame) -> list[str]:
    """èŽ·å–æ‰€æœ‰ç‰¹å¾åˆ—"""
    feature_cols = []
    for col in df.columns:
        if any(col.startswith(prefix) for prefix in FEATURE_PREFIXES):
            feature_cols.append(col)
    return sorted(feature_cols)


def show_data_info() -> None:
    """æ˜¾ç¤ºæ•°æ®ä¿¡æ¯"""
    if not TRAIN_CSV.exists():
        print("âŒ è®­ç»ƒæ•°æ®ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½æ•°æ®")
        return

    df = pd.read_csv(TRAIN_CSV)
    feature_cols = get_feature_columns(df)

    print("=" * 60)
    print("Hull Tactical æ•°æ®æ¦‚è§ˆ")
    print("=" * 60)
    print(f"è®­ç»ƒé›†å½¢çŠ¶: {df.shape}")
    print(f"ç‰¹å¾æ•°é‡: {len(feature_cols)}")
    print(f"ç›®æ ‡å˜é‡: {TARGET_COL}")
    print(f"\nç‰¹å¾åˆ—è¡¨:")
    for prefix in FEATURE_PREFIXES:
        cols = [c for c in feature_cols if c.startswith(prefix)]
        print(f"  {prefix}: {len(cols)} ä¸ª ({cols[:3]}...)")

    print(f"\nç›®æ ‡å˜é‡ç»Ÿè®¡:")
    print(df[TARGET_COL].describe())


def prepare_qlib_data() -> None:
    """å°† CSV è½¬æ¢ä¸º Qlib æ ¼å¼"""
    if not TRAIN_CSV.exists():
        raise FileNotFoundError(f"è®­ç»ƒæ•°æ®ä¸å­˜åœ¨: {TRAIN_CSV}")

    print(f"ðŸ“‚ è¯»å–è®­ç»ƒæ•°æ®: {TRAIN_CSV}")
    train_df = pd.read_csv(TRAIN_CSV)
    print(f"   å½¢çŠ¶: {train_df.shape}")

    # èŽ·å–ç‰¹å¾åˆ—
    feature_cols = get_feature_columns(train_df)
    print(f"   ç‰¹å¾æ•°é‡: {len(feature_cols)}")

    # Qlib éœ€è¦ datetime å’Œ instrument åˆ—
    # date_id æ˜¯æ•´æ•°ç´¢å¼•ï¼Œè½¬æ¢ä¸ºæ—¥æœŸ (å‡è®¾ä»Ž 1988-01-01 å¼€å§‹)
    base_date = pd.Timestamp("1988-01-01")
    train_df["datetime"] = base_date + pd.to_timedelta(train_df["date_id"], unit="D")
    train_df["instrument"] = "SPY"  # å•èµ„äº§ï¼Œä¼ªé€ ä¸€ä¸ªä»£ç 

    # é‡å‘½åç›®æ ‡åˆ—ä¸º Qlib æ ‡å‡†çš„ label
    if TARGET_COL in train_df.columns:
        train_df["label"] = train_df[TARGET_COL]

    # é€‰æ‹©éœ€è¦çš„åˆ—
    qlib_cols = ["datetime", "instrument"] + feature_cols + ["label"]
    qlib_df = train_df[qlib_cols].copy()

    # å¤„ç†ç¼ºå¤±å€¼
    qlib_df = qlib_df.fillna(0)

    # æ¸…ç†æ—§æ•°æ®
    if QLIB_DATA_DIR.exists():
        shutil.rmtree(QLIB_DATA_DIR)
    QLIB_DATA_DIR.mkdir(parents=True, exist_ok=True)

    # ä¸´æ—¶ç›®å½•ä¿å­˜ CSV
    csv_temp_dir = DATA_DIR / "qlib_csv"
    if csv_temp_dir.exists():
        shutil.rmtree(csv_temp_dir)
    csv_temp_dir.mkdir()

    # è®¾ç½®ç´¢å¼•å¹¶ä¿å­˜
    qlib_df = qlib_df.set_index(["instrument", "datetime"])
    for inst, group in qlib_df.groupby(level="instrument"):
        group = group.droplevel("instrument")
        group.index.name = "date"
        output_path = csv_temp_dir / f"{inst}.csv"
        group.to_csv(output_path)
        print(f"   ä¿å­˜: {output_path}")

    # è°ƒç”¨ Qlib dump å‘½ä»¤
    include_fields = ",".join(feature_cols + ["label"])
    cmd = (
        f"python -m qlib.run.dump_data "
        f"--csv_path {csv_temp_dir} "
        f"--qlib_dir {QLIB_DATA_DIR} "
        f"--include_fields {include_fields} "
        f"--date_field_name date"
    )

    print(f"\nðŸ”„ æ‰§è¡Œ Qlib æ•°æ®è½¬æ¢...")
    print(f"   å‘½ä»¤: {cmd}")
    exit_code = os.system(cmd)

    if exit_code == 0:
        print(f"\nâœ… æ•°æ®è½¬æ¢å®Œæˆï¼")
        print(f"   Qlib æ•°æ®ç›®å½•: {QLIB_DATA_DIR}")
    else:
        print(f"\nâŒ æ•°æ®è½¬æ¢å¤±è´¥ï¼Œé€€å‡ºç : {exit_code}")


if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "info":
        show_data_info()
    else:
        show_data_info()
        print("\n")
        prepare_qlib_data()
